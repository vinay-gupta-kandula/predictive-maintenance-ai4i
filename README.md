# AI-Driven Predictive Maintenance System (AI4I 2020)

## ğŸ“Œ Project Overview

This project develops an **end-to-end AI-driven predictive maintenance system** using the **AI4I 2020 industrial dataset**.
The objective is to **predict machine failure risk**, interpret the drivers of failure using explainable AI, and quantify the **business impact** of deploying such a system in an industrial setting.

The solution includes:

* Rigorous exploratory data analysis (EDA)
* Methodologically correct feature engineering
* Robust model training and validation for imbalanced data
* SHAP-based explainability
* Costâ€“benefit analysis tied to real business decisions
* An interactive Streamlit dashboard for decision-makers

This repository is **fully reproducible** and structured to reflect **industry-grade data science workflows**.

---

## ğŸ¯ Project Objectives

1. **Predict machine failure risk** using sensor and operational data
2. Handle **severely imbalanced classification** correctly
3. Prevent **data leakage** throughout the pipeline
4. Provide **interpretable insights** using SHAP
5. Quantify **financial value** via costâ€“benefit analysis
6. Deliver results through an **interactive dashboard**

---

## ğŸ“‚ Repository Structure

```
predictive-maintenance-ai4i/
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app.py                     # Streamlit interactive dashboard
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€executive_summary.pdf
â”‚   â”œâ”€â”€ video_demonstration.txt  
â”‚   â”œâ”€â”€ correlation_heatmap.png
â”‚   â””â”€â”€ top_at_risk_machines.png
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ ai4i2020.csv            # Original dataset
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ ai4i2020_features.csv  # Engineered features (generated)
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_model.joblib           # Trained XGBoost model
â”‚   â”œâ”€â”€ feature_list.json           # Final model feature list
â”‚   â”œâ”€â”€ imputer.joblib              # Median imputer
â”‚   â”œâ”€â”€ threshold.txt               # Optimized decision threshold
â”‚   â””â”€â”€ test_idx.npy                # Validation indices
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA.ipynb
â”‚   â”œâ”€â”€ 02_Feature_Engineering.ipynb
â”‚   â”œâ”€â”€ 03_Model_Training.ipynb
â”‚   â”œâ”€â”€ 04_SHAP_Insights.ipynb
â”‚   â””â”€â”€ 05_Cost_Benefit_Analysis.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ model_training.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

```

---

## ğŸ§ª Dataset Description

* **Dataset**: AI4I 2020 Predictive Maintenance Dataset
* **Samples**: 10,000 machines
* **Target**: `Machine_failure` (binary)
* **Class imbalance**: ~3.4% failures

### Important Design Decision

Each machine has **one independent observation** (no cycles or time history).
Therefore:

* **No artificial lag or rolling features are created**
* The problem is framed as **static failure risk prediction**
* This avoids fabricated temporal signals and ensures methodological correctness

---

## ğŸ” Notebooks Overview

### **01_EDA.ipynb â€” Exploratory Data Analysis**

* Data structure and distributions
* Missing value verification
* Outlier analysis
* Class imbalance analysis
* Correlation and sensor behavior visualization

**Key finding**:
Raw sensor values alone are not sufficient â†’ advanced feature engineering required.

---

### **02_Feature_Engineering.ipynb**

* Physics-based interaction features
* Load, wear, stress, and thermal proxies
* Nonlinear transformations (log, squared terms)
* Categorical binning and risk indicators
* Explicit leakage prevention
* Identifier columns (`UDI`, `Product_ID`) retained **only for dashboard use**

**Final model feature count**: **19**

---

### **03_Model_Training.ipynb**

* Models evaluated:

  * Random Forest
  * XGBoost
* Validation strategy:

  * Time-aware split for consistency
* Imbalance handling:

  * Class weighting
  * SMOTE (train-only)
* Metrics reported:

  * F1-score
  * Precision-Recall AUC
  * ROC-AUC
  * MCC
* **Threshold optimization** for F1

**Final model**: **XGBoost**

**Final performance (validation set)**:

* Optimized F1-score: **0.83**
* Precision-Recall AUC: **~0.78**

---

### **04_SHAP_Insights.ipynb**

* SHAP explainability for failure class only
* Global importance (beeswarm & bar plots)
* Local explanations (waterfall plots)

**Key drivers of failure**:

* Load and energy features
* Torqueâ€“wear interactions
* Thermal stress indicators
* Product type differences

---

### **05_Cost_Benefit_Analysis.ipynb**

* Business-aligned cost assumptions:

  * False Positive (preventive maintenance): **$500**
  * False Negative (unplanned breakdown): **$50,000**
* Evaluation on **hold-out validation set only**
* Uses optimized decision threshold

**Results**:

* Cost without model: **$1,600,000**
* Cost with model: **$450,000**
* **Net savings: $1,150,000**
* **Cost reduction: ~72%**

---

## ğŸ“Š Interactive Dashboard

The Streamlit dashboard enables:

* Machine-level failure probability inspection
* Risk categorization (Low / Medium / High)
* Business recommendations
* Expected cost calculation
* Probability smoothing to avoid unrealistic 0% / 100% certainty

### Launch Dashboard

```bash
streamlit run dashboard/app.py
```

---

## âš™ï¸ Environment Setup

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/vinay-gupta-kandula/predictive-maintenance-ai4i
cd predictive-maintenance-ai4i
```

### 2ï¸âƒ£ Create Virtual Environment


```bash
python -m venv .venv
```

**Activate the virtual environment**

**Windows (PowerShell)**

```powershell
.venv\Scripts\Activate
```

**Windows (CMD)**

```cmd
.venv\Scripts\activate.bat
```

**Linux / macOS**

```bash
source .venv/bin/activate
```


### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ How to Reproduce the Analysis

Run notebooks **in order**:

1. `01_EDA.ipynb`
2. `02_Feature_Engineering.ipynb`
3. `03_Model_Training.ipynb`
4. `04_SHAP_Insights.ipynb`
5. `05_Cost_Benefit_Analysis.ipynb`

All models and artifacts will be regenerated automatically.

---

## ğŸ“ˆ Key Results Summary

| Aspect          | Result             |
| --------------- | ------------------ |
| Final Model     | XGBoost            |
| Optimized F1    | **0.83**           |
| PR-AUC          | **~0.78**          |
| Missed Failures | 9 (validation set) |
| Net Savings     | **$1.15M**         |
| Cost Reduction  | **~72%**           |

---

# Reports

This folder contains final project deliverables.

- **executive_summary.pdf**: Business and management-level summary
- **correlation_heatmap.png**: Feature relationship analysis
- **top_at_risk_machines.png**: Dashboard output highlighting high-risk machines
- **video_demonstration.txt**: Link to 3â€“5 minute project walkthrough video

## Executive Report
- `executive_summary.pdf`

## Video Demonstration (3â€“5 minutes)
The video link is provided in:
- `video_demonstration.txt`

The video covers:
- End-to-end methodology walkthrough
- Interactive dashboard demonstration
- Key findings and business recommendations


---

## ğŸ§  Key Strengths of This Project

âœ” Methodologically correct (no fabricated time features)
âœ” Strong imbalance handling
âœ” Clear leakage prevention
âœ” Business-aligned evaluation
âœ” Explainable AI integration
âœ” Production-ready dashboard

---

## ğŸ‘¤ Author

**Vinay Gupta Kandula**
AI-Driven Predictive Maintenance Project




